CKA_1_Core_Concept

# 1. Introduce

### CKA (Certified Kubernetes Administrator)
- 쿠버네티스 관리자 인증 시험
    - 실습 위주로 되어있음
    - 기술의 작동 방식을 알아야함
    - HA Deolyment, Logging/Monitoring, Maintenance 등을 다룸
- 참고 사이트
    - Certified Kubernetes Administrator: https://www.cncf.io/certification/cka/
    - Exam Curriculum (Topics): https://github.com/cncf/curriculum
    - Candidate Handbook: https://www.cncf.io/certification/candidate-handbook
    - Exam Tips: http://training.linuxfoundation.org/go//Important-Tips-CKA-CKAD


# 2. Core Concepts

## Cluster Architecture
- Master Node: Kubernetes 관리를 담당
    - ETCD Cluster
        - 클러스터에 대한 정보를 저장 (어떤 컨테이너가 어떤 노드에 있는지 등)
        - 어떤 컨테이너가 어떤 선박에 있는지 등의 정보를 저장
        - Key-Value DB 
    - kube-scheduler    
        - 노드에서 애플리케이션과 컨테이너를 예약
        - 워커 노드의 컨디션, 로드할 수 있는 컨테이너 유형 등을 확인
    - Controll-Manager
        - 새로운 노드에 적재 및 컨테이너에 장애가 발생하지는 않는지 모니터링
    - kube-api 서버
        - 클러스터 내 모든 작업을 조정 (노드 제어, 복제, 컨트롤 등)
    - kubelet
        - kube-api 서버와 통신
        - kube-api 서버의 지시를 듣고, 노드에서 컨테이너를 생성하거나 제거
        - 노드, 컨테이너 상태 모니터링 
    - kube-proxy
        - 워커 노드 간에 통신 활성화
- Worker Node: 컨테이너를 로드, Docker 등의 런타임을 통해서 

### ETCD
- key-value 형태의 핵심 저장소
    - 빠른 읽기와 쓰기 제공
- 클러스터의 Nodes, PODs, Configs, Secrets, Accounts, Roles 등을 가짐
    - 클러스터 내 모든 작업을 업데이트
    - `kubectl get pod`와 같은 command도 모두 etcd에서 받는 내용
    - 만약 유실된다면 클러스터가 사용하는 모든 리소스가 미아가 됨
- 분산 저장소
    - 클러스터 형태로 여러 노드에 걸쳐 데이터를 저장 (고가용성 환경)
        - 여러 ETCD 인스턴스가 마스터 노드에 분산됨
    - 신뢰성과 일관성을 보장하기 위해서 `Raft 합의 알고리즘`사용
    - 컨센서스를 맞추는 것이 중요
        - Safety: 항상 올바른 결과를 리턴해야 합니다.
        - Available: 서버가 몇 대 다운되더라도 항상 응답해야 합니다.
        - Independent from timing: 네트워크 지연이 발생해도 로그의 일관성이 깨져서는 안됩니다.
        - Reactivity: 모든 서버에 복제되지 않았더라도 조건을 만족하면 빠르게 요청에 응답해야 합니다.

#### Raft 합의 알고리즘
- 구성 요소
    1. 리더(Leader): 클러스터의 상태를 관리하고 클라이언트의 요청을 처리하는 주 역할을 수행합니다.
    1. 팔로워(Follower): 리더의 상태를 따르며, 클라이언트 요청을 받기만 하고 처리하지는 않습니다.
    1. 후보자(Candidate): 새로운 리더를 선택하기 위해 선거에 참여합니다.
- 동작
    1. 주기적인 선거를 통해 리더를 선택 (election timeout이 끝난 노드가 후보자로 선정되어 선거를 요청)
    1. 리더는 클러스터의 합의를 이끌어내고, 변경 사항을 배포, 작업 스케줄링 (동기화를 통한 안정성과 일관성 유지)
    1. 리더가 동작 중인 동안에는 다른 노드가 팔로워로 동작
    1. 리더에 장애가 발생하면 선거가 다시 시작되어 새로운 리더를 선택
- 유의 사항
    1. 노드 개수를 홀수 개로 유지 > 리더 선출 과정이 안정적으로 동작
        - 후보자가 2이다? 투표 수가 홀수개가 됨

### kube-api 서버
- 클러스터 내의 모든 통신과 상호작용을 처리하는 api 서버
    - 사용자가 쿠버네티스와 상호작용할 수 있는 인터페이스를 제공
    - API 엔드포인트를 제공하며, 클러스터 관리, 리소스 생성, 애플리케이션 배포, 모니터링, 스케줄링 등 다양한 작업을 수행
    - 보안을 위해 인증(Authentication)과 권한 부여(Authorization)를 처리
- Pod create 시 진행 과정
    1. 유저 인증
    1. 요청 유효성 검사
    1. 정보 조회
    1. ETCD 업데이트
    1. 스케줄러에 등록 
    1. 적절한 워크 노드의 kubelet에 할당
- `kube-apiserver.service`를 통해서 구성 요소를 설정
    - 인증을 위한 SSL/TLS 인증서 설정
    - etcd 서버 정보 설정

#### API 서버
- 클라이언트 요청을 받아들이고, 해당 요청을 처리하여 클라이언트에게 응답을 반환
    - 보통 RESTful API를 구현하여 클라이언트와 상호작용. RESTful API는 일반적으로 HTTP 프로토콜을 사용하며, 요청과 응답은 JSON 또는 XML 형식으로 전송
- 주로 마이크로서비스 아키텍처 및 분산 시스템에서 사용
    - 마이크로 서비스 
        - 소프트웨어 어플리케이션을 나누는 작고 독립적인 단위
        - 각 서비스는 독립적으로 실행될 수 있음
        - 개별 서비스의 변경이 다른 서비스에 영향을 미치지 않고 배포 가능
        - API 서버를 통해 다른 마이크로서비스와 통신하여 상호작용


### Kube Controller Manager
- 다양한 컨트롤러들을 실행하고 관리하는 역할을 수행
- 클러스터의 상태를 지속적으로 모니터링, 원하는 상태를 유지하기 위해 여러 가지 컨트롤러를 kube-api 서버를 통해서 수행
- 종류 (Replication, Node, Job, Deployment, Namespace 등 )
    1. 레플리케이션 컨트롤러(Replication Controller)
        - 파드(Pod)의 복제본 수를 지속적으로 모니터링하고 관리
        - 지정된 복제본 수를 유지하기 위해 파드를 자동으로 생성, 수정 또는 삭제하여 애플리케이션의 가용성과 확장성을 관리
    1. 디플로이먼트 컨트롤러(Deployment Controller)
        - 디플로이먼트(Deployment) 리소스를 사용하여 애플리케이션의 배포와 롤링 업데이트를 관리
        - 새로운 버전의 애플리케이션을 점진적으로 배포하고 이전 버전의 애플리케이션을 천천히 제거하여 애플리케이션의 안정성을 유지
    1. 스테이트풀셋 컨트롤러(StatefulSet Controller)
        - 상태가 있는 애플리케이션(예: 데이터베이스)의 배포와 관리를 처리
        - 각 인스턴스에 고유한 식별자를 할당하고, 순차적인 배포 및 롤링 업데이트를 수행하여 데이터 일관성과 지속성을 유지
    1. 데몬셋 컨트롤러(DaemonSet Controller)
        - 각 워커 노드에 특정한 파드 인스턴스를 실행하는 데몬셋(DaemonSet)을 관리
        - 노드 수에 따라 파드 인스턴스가 자동으로 추가되거나 제거되므로, 클러스터의 모든 노드에 특정한 애플리케이션을 배치
- `kube-controller-manager.service`를 통해서 구성 요소 설정

#### StatefulSet
- 기존의 포드를 삭제하고 생성할 때 상태가 유지되지 않는 한계가 있음 (포드를 삭제하고 생성하면 완전히 새로운 가상환경이 시작됨)
- 필요에 따라 이러한 포드의 상태를 유지하고 싶을 수 있음 (응용프로그램의 로그나 기타 다른 정보들을 함께 저장하고자 하는 경우 단순히 PV를 하나 마운트해 이를 유지하기는 어려움)
- 스테이트풀셋으로 생성되는 포드는 영구 식별자를 가지고 상태를 유지할 수 있음
- 필요 케이스
    1. 안정적이고 고유한 네트워크 식별자가 필요한 경우
    1. 안정적이고 지속적인 스토리지를 사용해야 하는 경우
    1. 질서 정연한 포드의 배치와 확장을 원하는 경우
    1. 포드의 자동 롤링업데이트를 사용하기 원하는 경우

#### DemonSet
- 모든 노드 또는 특정한 노드에 특정한 파드(Pod)의 복사본이 실행
- 주로 로그 수집, 모니터링, 네트워킹과 같은 클러스터 전체적인 작업에 사용
- 노드가 클러스터에 추가되거나 제거될 때 자동으로 추가 또는 제거됨


### Kube Scheduler
- Pod의 요구 사항을 확인하고, 배치되는 노드를 결정
    - 최적의 노드에 할당하여 클러스터의 리소스 효율성을 향상, 노드 장애 시 자동으로 다른 노드로 옮기는 등의 고가용성 제공
    - 스케줄러는 파드의 예약 상태를 관리하고, 파드가 정상적으로 스케줄링되고 실행되도록 확인함. 
- Pod 요구 사항
    1. 리소스 요구 사항: 파드가 필요로 하는 CPU, 메모리 등의 리소스 양을 지정합니다.
    1. 볼륨 요구 사항: 파드가 사용하는 볼륨(예: 디스크, 네트워크 스토리지)의 종류, 크기, 마운트 포인트 등을 지정합니다. 
    1. Affinity/Anti-Affinity: 파드가 특정 노드와 함께 스케줄링되도록 하는 Affinity(친화성) 규칙이나 특정 노드와 함께 스케줄링되지 않도록 하는 Anti-Affinity(반친화성) 규칙을 정의할 수 있습니다. 이를 통해 파드 간의 관련성이나 격리성을 제어할 수 있습니다.
    1. Node Selector: 특정 노드에 레이블을 지정하고, 파드는 해당 노드에만 스케줄링될 수 있습니다.
    1. Node Affinity: 특정 노드와 관련된 규칙을 사용하여 파드를 할당할 수 있습니다. 
    1. 서비스 포트 포워딩: 파드에 외부로 노출되는 서비스 포트를 정의할 수 있습니다. 이를 통해 외부 클라이언트가 파드에 접근할 수 있게 됩니다.
- Node 선택
    - Filter Node: 적절한 노드 후보를 선별하는 과정
    - Rank Node: 후보 노드 중 최종적으로 Pod를 할당할 노드를 선택하는 과정 (후보 노드들을 점수화)

### Kubelet
- 클러스터의 각 노드에서 실행되는 에이전트 
- 역할
    1. Pod 실행: API 서버로부터 할당된 Pod목록을 받아와 노드에 실행
    1. Resource 관리: 노드의 리소스(CPU, 메모리, 디스크 등)를 모니터링하고 관리
    1. 상태 보고: 주기적으로 노드의 상태와 파드의 상태를 API 서버에 보고
    1. 라이프사이클 관리: 파드의 생성, 시작, 종료, 재시작 등의 이벤트를 감지하고 필요한 작업을 수행
    1. 볼륨 마운트: 파드에 정의된 볼륨(Volume)을 마운트하고, 컨테이너에 볼륨을 제공
    1. 보안 및 인증: API 서버와의 통신에 사용되는 인증 정보를 관리하고, 파드의 보안 정책을 적용

#### 로그
- 애플리케이션 및 시스템의 동작 및 문제점을 식별하기 위함
    - Pod 단위로 수집됨 / Node, Pod, Service 등에 변경 사항 및 이벤트도 로그로 남김
    - 로그 수집 에이전트 > 로그 저장소 > 로그 검색 및 분석
        - 로그 수집 에이전트: Fluentd, Fluent Bit, Logstash
        - 로그 저장소: Elasticsearch, Splunk, Grafana Loki
        - 로그 검색 및 분석: Elastic Stack (Elasticsearch, kubana), Grafana Loki
    - 기본적으로 Pod의 로그 등의 정보는 Node에 보관
        - 플러그인을 설치로 중앙 집중식 로그 수집 / 데이터 보존 및 백업 / 로그 분석 및 모니터링 이 가능
- Metrics Server
    - Kubernetes 리소스 사용량 및 성능 지표를 수집/노출
        - Resource 들의 CPU/MEM 사용량, 네트워크 트래픽 등의 지표를 수집
        - Node > kubelet > cAdvisor > Kubelet API > Metrics Sever
    - GitHub를 통한 설치 필요

### kube-proxy
- 파드 간의 네트워크 연결 및 로드 밸런싱을 처리하여 클러스터 내의 서비스의 안정성과 가용성을 유지
    - 기본적으로 모든 노드에서 실행됨
    - 다른 노드 간의 Pod를 연결하는 것에 도움
    - Load Balancing, Service, Pod
- 주요 기능
    1. 서비스 디스커버리(Service Discovery)
        - 클러스터 내에서 실행 중인 애플리케이션의 서비스를 자동으로 탐지하고 찾을 수 있도록 도와주는 기능
        - 애플리케이션은 서비스의 가상 IP 주소를 통해 서비스에 접근하고, 클러스터 내부의 Pod들과 통신
        - 기존과 비교
            - 기존: 서버A(프론트)-서버B(백엔드)로 구분함
            - 현재: 어떤 노드에 애플리케이션이 있는지 모름 (K8s가 동적으로 관리)
            - 따라서 애플리케이션의 조합을 만들 필요가 있음
    1. 로드 밸런싱(Load Balancing)
        - 클러스터 내부에서 동작하는 서비스에 대한 요청은 kube-proxy가 해당 서비스의 파드로 분산
        - 로드 밸런싱은 라운드 로빈 방식이나 IPVS 같은 로드 밸런서를 사용하여 구현
    1. 네트워크 프록시(Network Proxy)
        - 클러스터 내부의 파드는 내부 IP 주소를 사용하여 다른 파드와 통신

### POD가 실행되는 순서
1. 파드 정의 작성: 파드를 실행하기 위해 YAML 또는 JSON 형식으로 파드 정의 파일을 작성
1. `API 서버`와의 통신: 파드 정의 파일을 API 서버에 제출. API 서버는 파드를 클러스터의 상태 정보와 비교하여 유효성을 검사하고, 파드의 상태와 구성 정보를 저장.
1. 스케줄링: API 서버는 `스케줄러(Scheduler)`를 통해 파드를 할당할 노드를 선택
1. `Kubelet`에게 할당 요청: 선택된 노드의 Kubelet은 API 서버로부터 할당된 파드를 확인하고, 파드를 실행하기 위해 `컨테이너 런타임(Docker, containerd 등)`에게 실행 요청을 전달.
1. 컨테이너 실행: 컨테이너 런타임은 파드에 정의된 컨테이너 이미지를 가져와 컨테이너를 실행합니다. 이 때, Kubelet은 컨테이너의 라이프사이클 관리, 리소스 할당, 네트워크 설정 등을 담당.
1. 파드 상태 갱신: Kubelet은 파드의 상태를 주기적으로 감지하고, API 서버에 상태 업데이트를 보고합니다. 파드의 상태는 "Pending"에서 "Running" 또는 "Failed"로 변경될 수 있습니다.
1. 서비스 포트 포워딩: 만약 파드가 외부로 노출되어야 하는 서비스 포트를 정의했다면, Kube-proxy 컴포넌트는 해당 포트를 감시하고 요청을 파드로 포워딩합니다.

#### 컨테이너 런타임
- 컨테이너 실행, 자원 관리 (CPU, 메모리, 디스크, 네트워크 등의 자원을 컨테이너에 할당), 네트워킹 (컨테이너에 IP주소를 할당), 저장소 관리
- Docker vs Containerd
    - Docker는 build, run, image관리 등에서 좀 더 편의성이 잘 제공되어있고, CI환경이나 kubernetes환경이 아닌 곳에서 더 편리하게 사용 가능
    - Containerd는 중간에 layer가 적어 가벼움. 제한된 리소스를 써야하는 환경이라면 좀 더 좋을 것이지만, 개발 편의성이 떨어진다.


<img src="https://user-images.githubusercontent.com/40620421/244922843-9f6818fb-b324-4a47-b44a-d425ba7a9b49.png" width="600">