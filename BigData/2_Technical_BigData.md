2_Technical_BigData

<p align="center">
<img src="https://user-images.githubusercontent.com/40620421/183598835-ebf8d4ba-354d-4b02-8ccd-a7d1f2d29018.jpg" width="300">

본 내용은 해당 도서를 참고하여 정리한 내용입니다.
</p>

<br/>
<br/>
<br/>

# 2. 빅데이터의 탐색

## 2-1. 크로스 집계의 기본
- 데이터 시각화에서 먼저 기본이 되는 것이 크로스 집계
- `크로스 집계`: 트랜잭션 테이블에서 크로스 테이블로 변환하는 과정
    1. 크로스 테이블: 행과 열이 교차하는 부분에 숫자 데이터가 들어가는 테이블
    1. 트랜잭션 테이블: 행을 기준으로 데이터가 추가되는 테이블

<img src="https://user-images.githubusercontent.com/40620421/185924635-c1f3f12d-b655-49ee-9382-6ba4b359acf0.png" width="500">

### SQL에 의한 테이블 집계
- 대량의 데이터를 크로스 집계하기 위해 SQL을 활용
    - 데이터 양이 너무 많으면 피벗 테이블을 통한 크로스 집계가 어려움
- SQL을 통해서 크로스 테이블이 아닌 트랜잭션 테이블의 형태로 얻고, 이를 크로스 집계함으로써 임의의 크로스 테이블을 얻을 수 있음
```sql
SELECT 매출일, 점포 ID, 금액 FROM 판매이력
```
매출일|점포ID|고객ID|금액
--|--|--|--
2022-08-01|1|10|60000
2022-08-01|1|11|50000
2022-08-01|2|12|30000
2022-08-02|1|13|120000
2022-08-02|2|14|50000
2022-08-02|2|15|40000

점포ID\매출일|2022-08-01|2022-08-02
--|--|--
1|110000|120000
2|30000|90000

- 데이터 집계를 `SQL`로 하고, 크로스 집계를 `시각화 도구`로 함으로써 이론상 무한히 많은 데이터가 있더라도 크로스 집계가 가능하다
    - `데이터 집계의 프로세스`: SQL로 집계
    - `시각화 프로세스`: 시각화 도구로 크로스 집계

## 2-2. 열 지향 스토리지에 의한 고속화
대량의 데이터를 신속하게 집계하기 위한 DB 구조

### DB 지연 줄이기
- RDB는 메모리가 부족하면 급격히 성능이 저하된다
- `MPP 기술`
    - 고속화를 위해 사용되는 기법이 `압축과 분산`
    - 데이터를 최대한 압축한 후, 여러 디스크에 분산함으로써 데이터 로드의 지연을 줄인다
    - 멀티 코어를 활용하여 디스크 I/O를 병렬처리
    - 하드웨어 수준에서 균형된 CPU와 디스크를 가진 DB를 `MPP 데이터베이스`라고 함
    - Amazon RedShift, Google BigQuery

### 열 지향 DB 접근

#### 행 지향 DB
- 일반적으로 많이 사용되는 DB
- 데이터 검색을 위해서는 모든 레코드를 가져와야함 → 성능 저하
- `Index`를 통해 데이터 검색을 고속화
- 하지만 데이터 분석에서는 어떤 칼럼이 사용되는지 미리 알 수 없기 때문에 Index가 큰 도움이 되지 않음

#### Index
- 장점
    - 테이블을 조회하는 속도와 성능 향상
    - 시스템 부하를 줄임
- 단점
    - 인덱스를 관리하기 위한 추가 저장 공간 필요
    - 인덱스를 항상 정렬된 상태로 유지하기에 추가 작업이 필요
    - 인덱스를 잘못 사용할 경우 역효과가 날 수 있다.
- Index 권장 케이스
    - 데이터 양이 많은 테이블
    - 업데이트보다 조회가 잦은 테이블
    - 조건문이나 정렬이 잦은 테이블
- Index 자료 구조
    - Hash 인덱스 알고리즘, B-Tree 인덱스 알고리즘, B+Tree 인덱스 알고리즘 (균형 트리)

#### 열 지향 DB
- 데이터를 미리 `칼럼 단위`로 정리해 둠으로써 필요한 칼럼만 로드하여 디스크 I/O를 줄임
- 일부 칼럼만이 집계 대상이 될 때 유용함
- `압축 효율`이 우수함 (같은 칼럼에는 유사한 데이터가 나열되기 때문)
- `MPP`를 통해 하나의 쿼리를 다수의 작은 태스크로 분해하고 병렬로 실행
    - 디스크로부터 로드가 병목 현상이 발생하지 않도록 데이터가 고르게 분산되어 있어야함

## 2-3. 애드 혹 분석과 시각화 도구

### 대시보드 도구
- 새로운 그래프를 쉽게 추가할 수 있는 도구
- 최신의 집계 결과를 즉시 확인할 수 있길 기대
- 정해진 지표의 일상적인 변화를 모니터링

### BI 도구
- 대화형 데이터 탐색이 중요시됨
- ex. 몇개월 단위의 장기적인 데이터 추이를 시각화, 집계의 조건을 세부적으로 바꿈
- Tableau

## 2-4. 데이터 마트의 기본 구조
BI 도구에서 대화형으로 데이터를 참고하려면, 시각화 정보만을 모은 데이터 마트가 필수

### 시각화에 적합한 데이터 마트 만들기
- `OLAP`/online analytical processing
    - 사용자가 다차원 정보에 접근하여 대화식으로 정보를 분석하도록 지원
- `다차원 모델`
    - 데이터 집계를 효율화하는 접근 방법 중 하나
    - 데이터 분석을 위해 만들어진 다차원 데이터를 `OLAP 큐브`라고 하고, 그것을 크로스 집계하는 구조가 `OLAP`
    - 크로스 집계의 모든 조합을 미리 계산하여 DB안에 캐시해두고, 쿼리가 실행되면 집계된 결과를 반환하는 구조
    - 데이터 마트가 이전에 가지고 있던 구조
- `MPP DB와 비정규화 테이블`
    - MPP DB와 인 메모리 DB 등의 보급으로 사전에 계산할 필요가 없음
    - MPP DB에 다차원 모델의 개념이 없기 때문에 비정규화 테이블을 준비
    - 시각화에 적합한 데이터 마트를 만드는 것은 BI 도구를 윈한 `비정규화 테이블`을 만드는 프로세스

### 테이블을 비정규화하기

#### 정규화 테이블
- `트랜잭션`: 시간과 함께 생성되는 데이터
    - 시간과 함께 생성되기에 변하지 않음
- `마스터`: 트랜잭션에서 참고되는 각종 정보
    - 상황에 따라 일부 데이터가 업데이트됨
    - 고객 테이블에서 고객ID는 변경되지 않지만, 고객 주소와 같은 속성은 변경될 수 있음

#### 비정규화 테이블
- 과거
    - DW에서는 트랜잭션과 마스터를 `팩트 테이블`과 `디멘젼 테이블`이라고 칭함
    - DM를 만들 때 팩트 테이블을 중심으로 여러 디멘젼 테이블을 결합하는 것이 좋음 (`스타 스키마`)
- 현재
    - MPP DB와 열 지향 스토리지 시스템의 발달로 칼럼수가 아무리 늘어나도 성능에 영향을 주지 않는다
    - 처음부터 팩트 테이블에 모든 칼럼을 포함해두고, 쿼리 실행 시 테이블 결합을 하지 않는다
    - 장점
        1. 빠른 데이터 조회 (Join 비용이 줄어들기 때문)
        1. 데이터 조회 쿼리의 간단화
    - 단점
        1. 데이터 갱신이나 삽입 비용이 높음
        1. 데이터 무결성을 해침
        1. 데이터 중복 저장으로 인한 추가 저장공간 확보

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fk.kakaocdn.net%2Fdn%2FbJUNWP%2FbtqE2twgz5B%2FZ9qC1T74uCQ1CyAbKnUG60%2Fimg.png" width="500">

# 3. 빅데이터의 분산 처리

## 3-1. 대규모 분산 처리 프레임워크
다수의 컴퓨터에 데이터 처리를 분산하기 위해서는 그 실행을 관리하는 프레임 워크가 필요하다.  
`Hadoop`, `Spark` 중심

### 데이터 구조화

<img src="https://user-images.githubusercontent.com/40620421/186179295-30d91728-6b4a-4246-bc20-d3c544b77397.png" width="500">

- `구조화 데이터`: 스키마가 명확하게 정의된 데이터
    - 스키마: 테이블의 칼럼 명, 데이터 타입, 테이블 간의 관계 등을 정의
    - 기존 DW에서 데이터를 축척하는 일반적인 방식
- `비구조화 데이터`: 스키마가 없는 데이터
    - 자연 언어로 작성된 텍스트 데이터, 이미지, 동영상 등
    - 이 상태로는 SQL로 제대로 집계할 수 없음
    - 이 데이터를 분산 스토리지 등에 저장하고 그것을 분산 시스템에서 처리하는 것이 `데이터 레이크`의 개념
- `스키마리스 데이터`: 기본 서식은 있지만, 스키마가 정의되지 않음
    - CSV, JSON, XML 등
    - 칼럼 수나 데이터 타입은 명확하지 않음
    - NoSQL DB에서 활용

#### 열 지향 스토리지
- `MPP DB`: 제품에 따라 스토리지 형식이 고정되어 사용자가 상세히 몰라도됨
- `Hadoop`: 직접 열 지향 스토리지 형식을 선택
    - `ORC`: 구조화 데이터를 위한 열 지향 스토리지. 처음 스키마를 정한 후 데이터 저장.
    - `Parquet`: 스키마리스에 가까운 데이터 구조. JSON과 같은 데이터도 그대로 저장 가능.

### Hadoop
- 대규모 분산시스템을 구축하기 위한 공통 플랫폼
- 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체 (단일 소프트 웨어 X)
- Why Hadoop? 🤔
    1. 접근성과 비용 절감  
    접근성이 뛰어나서 유연한 방식으로 하드웨어를 사용할 수 있음 → 고가의 신뢰도 높은 하드웨어 만을 추구하지 않음 → 비용 절감
    기존 DB는 소프트웨어와 하드웨어가 비싸다
        
    2. 빅데이터에 대한 내결함성  
    기본적으로 HDFS는 파일을 `3군데 저장 `
    → 공간적으로 비효율적이다? 만약 한 데이터 노드에서 데이터를 구성할 수 있다면? 성능적 이득을 볼 수 있음
    → 왜 3개? 내결함성+성능 실험적으로 알맞음
        
    3. 확장성  
    하드웨어를 추가했을 때, 성능이 리니어하게 증가한다.
        
    4. 읽기 시점 스키마  
    기존에 쓰기 시점 스키마에서 벗어나, 하둡이나 NoSQL은 데이터를 읽을 때 데이터의 본질을 파악한다.
    데이터를 소비자에게 데이터의 성질을 맡기는 시스템. (데이터로 뭘하기 전까진 데이터로 무엇을 할지 정확히 알 수 없다.)
- Why Java? 🤔
    1. Java의 GC가 가장 성능이 좋음 (빅데이터를 다루기에 메모리 관점 중요)
    2. Java가 디버깅이 쉬움
    3. Hadoop이 Nutch 프로그램에서 발전 되었는데, 그것이 Java 기반
- 하둡 2 vs 3
    - 이레이저코딩 도입하여 기존의 블록 복제를 대체하는 방식   
        ⇒ 1GB 저장: 3GB → 1.5GB  
        ⇒ 데이터 손실 시 복구할 수 있는 기법. 데이터 복제를 대체하지는 않음
    - 2개 이상의 네임노드를 지원

참고  
https://intrepidgeeks.com/tutorial/hedou-you-should-know  
https://deep-flame.tistory.com/9

#### HDFS (Hadoop Distributed File System)
- 데이터를 블록으로 나누어 저장하는 `분산 파일 시스템`
- 수정, 삭제 불가 → 한 번쓰고, 여러 번 읽는 구조에 적합함
- 마스터-워커 패턴 (Name Node가 쇼를 하고, Data Node가 모든 일을 한다)
    - `Name Node`
        메타 데이터 (모든 파일과 디렉토리에 대한 정보)
        Name Node가 없다면 Data Node에 있는 데이터를 불러올 수 없음
        따라서 Name Node의 정보를 지속적으로 백업

    - `Data Node`
        클라이언트나 네임노드의 요청에 블록을 저장하고, 탐색
- `HDFS의 기본 블록 사이즈 128MB` 왜 이렇게 큼?
    - 탐색 비용 최소화: 블록의 시작점을 탐색하는 데에 걸리는 시간을 줄일 수 있음

    - 전송 비용 최소화: 한 데이터 노드에서 데이터를 모두 구성할 수 있다면 데이터 블락을 한데로 모으는 시간을 최소화할 수 있음

    - 대용량 데이터를 기반으로 함

<img src="https://blog.kakaocdn.net/dn/baTHVO/btrqsdMTHNX/bChgeqd831xlqEc1naDzR0/img.gif" width="500">

```
Write-1. 데이터를 블록으로 나눈다.
Write-2. 블록을 저장하려는 클라이언트는 네임노드를 통해 블록이 저장될 데이터 노드의 목록을 받는다.
Write-3. 클라이언트는 첫 번째 데이터노드에 블록을 쓰고, 차례대로 다음 데이터노드로 파이프라인을 통해 데이터를 흘려보낸다. (네임노드는 데이터노드의 가용 저장 공간을 고려하여 파이프라인을 구성)
Read-1. 네임노드를 통해 읽을 블록을 가지고 있는 데이터 노드의 목록을 받는다.
Read-2. 최대한 가까운 곳에 위치한 데이터노드로부터 데이터를 읽어들인다.
```

#### YARN (Yet Another Resource Negotiator)
- CPU나 메모리 등의 계산 리소스를 관리하는 시스템
- 리소스 매니저와 노드 메니지가 서로 통신하며 통해 수많은 워크 노드의 리소스를 관리
    - `리소스 매니저`  
        실행되는 애플리케이션을 예약하는 중앙 관리 시스템
    - `노드 매니저`  
        컨테이너를 시작하고 리소스 사용량(CPU, 메모리, 디스크, 네트워크)를 모니터링하고 리소스 매니저에 보고

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBN83W%2FbtrqnklKtxC%2FRLCe086rprV5phLHIIruFK%2Fimg.png" width="500">

```
Assign-1. 클라이언트가 리소스 매니저에 어플리케이션을 제출한다.
Assign-2. 워커 노드 내 어플리케이션 마스터는 리소스 매니저에게 어플리케이션을 실행할 리소스 할당을 요청한다. 
Assign-3. 이때 연산 수행에 필요한 자원은 서로 다른 컨테이너 단위로 분할되어 어플리케이션 마스터에게 전달된다.

Run-1. 어플리케이션 마스터는 노드 메니저에게 컨테이너의 실행 명령을 전달한다.
Run-2. 코드가 컨테이너에서 실행된다.
Run-3. 어플리케이션이 종료되면 어플리케이션 마스터는 리소스메니저에서 자신을 제거하고 셧다운된다.
```

#### ZooKeeper
- Hadoop의 분산처리 환경에서 `조율을 관리하는 코디네이션 서비스`
- 복수의 컴퓨터가 네트워크를 통해 통신하며 하나의 목적을 위해 서로간에 상호작용한다. 이때 마치 하나인 것처럼 동작하는 시스템처럼 합의를 이끌어내는 서비스
- 고가용성 확보, 태스크 조율, 상태 추적, 일반적인 설정 파라미터 값 지정 수행

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FkPeUK%2FbtrKvEx2xrY%2FPfX6CkmkvXsuIuRhETmKNk%2Fimg.png" >

아키
1. 클라이언트가 주키퍼 서버에 데이터를 업데이트한다. (Client B > Server D)
2. Leader 서버에서 이를 알린다.
3. Leader 서버에서는 Broadcast 형식으로 Follower 서버들에게 알린다.
4. 모든 서버에서 데이터가 일관된 상태로 유지된다.

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F1jbGE%2FbtrKsO2SjhG%2FLknJjwgxd0kAVJRWwCRLZk%2Fimg.jpg">

`znode`
- 데이터를 저장하기 위해 사용하는 가장 작은 단위의 데이터 저장 객체
- 모든 데이터가 메모리에 저장되며, 최대 1MB로 제한적 → `설정 값이나 리소스 상태` 등을 저장하는 매우 유용
- Zookeeper는 여러 서버에 분산되어 있는 znode를 관리한다.
- 종류
    - Persistent Node: 명시적으로 삭제되기 전까지 존재.
    - Ephemeral Node: 세션이 유지되는 동안 존재. 자식 노드를 가질 수 없다


#### MapReduce
- 분산 시스템에서 데이터 처리를 하는 시스템
- 비구조화 데이터를 가공하는 데 적합
- `Map Task`: 파일에 있는 각 레코드를 Key-Value형태로 변환한 결과를 반환한다.
- `Reduce Task`: 하나의 키에 대한 여러 값의 집계 또는 결합해서 입력값의 개수보다 더 작은 개수의 결과값을 산출한다.

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhfcnK%2FbtrqsFwXfmJ%2F46fgAZoKuSSWyViDgDMVMK%2Fimg.png" width="500">

```
예) 단어 개수 세기
Map. (단어, 1)의 Key-Value 구조의 리스트를 반환한다.
Shuffling. 단어 중심으로 데이터를 데이터를 모은다.
Reduce. (단어, count)를 수행하여 각 블록에서 특정 단어가 몇 번 나왔는지 계산한다.
```

#### Hive
- SQL 등의 쿼리 언어에 의한 데이터 집계 가능 (SQL-on-Hadoop)
    - 데이터가 저장된 HDFS에 접근하기 어려움
- 쿼리를 자동으로 MapReduce 프로그램으로 변환하는 소프트웨어로 개발됨 (Spark도 지원되긴 함)  
    → MapReduce가 대량의 배치 처리를 위한 시스템이다.  
    → `초기 지연이 너무 크기` 때문에 작은 쿼리 실행에는 적합하지 않다.  
    → `배치 처리`에 적합  
- Hive는 DB가 아닌 데이터 처리를 위한 배치 처리 구조이다. (쿼리 성능 고민 필요)

👉 `메타 스토어`
- HDFS에 적재된 데이터의 메타정보(파일 위치, 이름 등)을 Table Schema 정보와 함께 메타스토어에 등록  
→ Hive 쿼리를 수행할 때 메타스토어의 정보를 참조하여 마치 RDBMS에서 데이터를 조회하는 것 같은 기능 제공

👉 `아키텍처`  

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbMBATj%2FbtrKwbh45zy%2FD0q0JwtPs5MKOUFCPbKG41%2Fimg.png" width="500">

하이브는 사용자 쿼리를 파싱하고, `최적화`해서 하나 이상의 연쇄 배치 연산으로 `컴파일`하며 이를 클러스터에서 실행한다. 
1. HiveQL 문을 Driver가 받고, 메타스토어의 정보를 활용하여 적합한 형태로 컴파일
2. 컴파일된 SQL을 실행 엔진으로 실행
3. 리소스 매니저가 클러스터 자원을 적절히 활용하여 실행
4. 원천 데이터는 HDFS를 활용
5. 결과를 사용자에게 변환 

👉 `데이터 저장 방법`  
- **SerDe**: Hive가 데이터를 해석하는 방법을 제공
    - Avro, ORC, RegEx, Thrift, Parquet, CSV, JSONSerDe
    - Parquet: 열 기반 데이터 구조 (인코딩 효율이 높음, 쿼리 성능이 높음)
- 쿼리 성능 향상을 위한 데이터 형식
    - **Partition**
        - Column 정보를 이용하여 폴더 단위로 데이터가 생성 (큰 데이터를 작은 데이터로 쪼갬)
        - 기본적으로 테이블의 모든 row를 읽음 (파티션이 있다면 폴더의 데이터만 읽어 성능 향상)
        - Partition 범주가 너무 많지 않도록 주의
    - **Bucket**
        - 지정된 칼럼의 값을 해쉬 처리하고, 데이터를 지정한 수의 파일로 나누어 저장
        - 범주가 40이고, 버켓이 20이면 한 버켓이 2개의 범주씩 쌓인다
        - 조인 키로 버킷을 생성해두면 생성된 버킷 중 필요한 버킷만 조회하면 됨 → 성능 향상
    - **Skew**
        - 주로 많이 들어오는 데이터가 몰릴 때 사용 (A, B 외 나머지 총 3개의 디렉토리나 파일로 구별)
        - 네임노드의 관리 포인트가 줄어든다.


#### Impala, Presto
- 대화형의 쿼리 실행 전문
- 초기 지연이 적음 → Hive를 통해서 구조화 데이터를 만들고, 뒤에 활용됨

👉 **Impala**
1. SQL, HiveQL 모두 사용 가능
2. HDFS에 저장 + Hive 메타스토어를 사용
3. C++을 통해 구현하여 속도 개선 + 실시간 데이터 처리 + `데이터 소비자` 
4. 새로 프로젝트를 시작한다면 좋은 옵션

👉 **Presto**
1. 페타바이트 급의 데이터처리 SQL 사용
2. 대기 시간에 최적화, 쿼리 처리량 메모리 양에 제한 + `데이터 소비자` 
3. 기존의 진행 중인 데이터 시스템을 수정할 필요없이 기존의 생태계와 원활하게 통합되도록 설계
4. 컴퓨팅과 스토리지가 별도로 수행되어서 클라우드 환경에 적합하다.


### Spark
- MapRduce의 단점을 극복하기 위한 데이터 처리 시스템
    - Map Reduce의 단점
        - 맵리듀스로 복잡한 파이프라인을 조합하는 것은 많은 분석가들에게 부담
        - 많은 양의 디스크 기반 I/O를 수행한다. 따라서 다중 단계 파이프라인은 I/O 비용이 매우 많이 든다.
- 대량의 `메모리를 활용`하여 고속화를 실행
    - 가능한 많은 데이터를 메모리상에 올린 상태로 두어 디스크에는 아무것도 기록하지 않는다.
    - 컴퓨터가 비정상 종료하는 경우에도, 그때 처리를 다시 시도해서 중간 데이터를 다시 생성하면 된다.
- 특징
    - JDK 필요. Spark SQL 이용
    - 다양한 스크립트 언어 지원(Java, Scala, Python, R 등)
    - MapReduce 개선 사항으로 설계됨 → Hadoop과 호환성이 좋음

👉 **RDD vs DataFrame vs Dataset**
- `RDD (Resilient Distributed Datasets)`
    - 스키마가 없는 분산된 데이터 모음 (스키마 수동 정의)
    - 메모리 내부에서 데이터 손실하더라도 재연산으로 복구할 수 있는 데이터 집합 → 내결함성 방식
    - Lineage(DAG) + 읽기전용 → 데이터 처리의 관계성을 명확히 할 수 있음 → 특정 RDD에서 메모리가 유실되더라도 복기할 수 있음
- `DataFrame`
    - 분산된 데이터를 Column으로 모은 데이터 구조
    - 관계형 테이블과 같은 구조 → 대용량 데이터를 좀 더 쉽게 처리
    - 스키마 자동 정의
- `DataSet`
    - DataFrame에서의 확장 (Dataset[Row] == DataFrame)
    - Scala and Java에서만 활용가능
    - 스키마 자동 정의

👉 **Spark 연산 과정**  
- Logical Plan
    연산 단계에서 사용될 DataFrame이나 Column이 실제로 존재하는지에 대한 검사를 시행한다.
- Physical Plan
    1. 클러스터에서 Logical Plan을 어떻게 실행할지 정의한다. 
    2. 그 방법은 다양한 방법을 시도해보고, Cost Model을 이용하여 비교한다. 
    ⇒ `Best Physical Plan`을 선택

<img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbOYdlK%2Fbtrq7ao3mSU%2FLbu13eBKp3vQuPfkamwjU0%2Fimg.jpg">

👉 **Lazy Ealuation**  
`Action이 시작되는 시점`에 Transformation끼리 연계를 파악해 실행 계획을 최적화 (physical plan)
- Transformation: 새로운 RDD를 생성하는 동작 (map, filter, distinct)
- Action: 기록된 모든 작업을 실제로 수행하는 연산 (first, show, collect, count)

<img src="https://user-images.githubusercontent.com/40620421/186442906-7503b6ce-e867-43c2-9fa8-17fba7b7d9c7.png" width="500">

```scala
// 예시 1
val df1 = (1 to 100000).toList.toDF("col1")
df1.withColumn("col2",lit(2)).drop("col2").explain(true) // col2에 대한 처리는 생략된다.

// 예시 2
val arr = Array(1,2,3,4,5,6)
arr.filter(_<=4).filter(_%2==0).first 
// eager: [2,4]를 구한 후 2를 구함
// lazy: 첫번째 값만 구하면 되기때문에 2만 구함
```

## 3-2. 쿼리 엔진
SQL-on-Hadoop에 의한 데이터 처리의 구체적인 예  

### 데이터 마트 구축의 파이프라인
- 목표는 데이터 마트에서 `빠른 조회`
- 파이프라인  
    지연 시간이 긴 Hive로 데이터를 조회하기 빠른 형태로 구조화하고, 지연시간이 적은 Presto로 데이터를 조회하는 구조
    - `Hive`: 분산 스토리지 내 비구조화 데이터 → 구조화 데이터 → 열 지향 스토리지 형식으로 저장
    - `Presto`: 완성한 구조화 데이터를 결합, 집계하고 비정규화 테이블로 데이터 마트에 내보낸다

<img src="https://user-images.githubusercontent.com/40620421/186680026-d52e7605-9ea2-47a9-87e0-d35e199999ca.png" width="500">

<br/>
<br/>

#### Hive에 의한 구조화 데이터 만들기

```sql
-- 예시 1) 바로 조회
SELECT status, count(*) cnt FROM access_log_csv
-- 8.664 seconds (바로 집계는 비효율적)


-- 예시 2) 구조화 진행 후 조회
CREATE TABLE access_log_orc STORED AS ORC AS
SELECT cast(TIME as timestamp) time, request, status FROM access_log_csv
-- 15.993 seconds (시간이 걸리는 프로세스임으로 Hive와 같은 배치형 쿼리 엔진이 적합)

SELECT status, count(*) cnt FROM access_log_csv
-- 1.567 seconds (구조화 데이터를 집계하는 것이 훨씬 효율적)
```

Hive로 비정규화 테이블 작성  
- 데이터 마트를 구축하기 위해 비정규화 테이블을 작성한다
- 시간이 오래 걸리는 작업인 경우 지연시간이 총 작업시간에 큰 영향을 주지 않고, 리소스 이용 효율을 높일 수 있어 Hive를 활용하는 것이 원칙적이다

Hive 쿼리 개선  
1. 서브 쿼리 안에서 레코드 수 줄이기

    ```sql 
    -- 비효율적인 쿼리 (전체 데이터를 조회한 후 Filter)
    SELECT ... 
    FROM access_log a 
    JOIN users b ON b.id=a.user_id
    WHERE b.created_at = '2017-01-01'

    -- 보다 효율적인 쿼리 (초기에 팩트 테이블을 작게한다)
    SELECT ... 
    FROM (
        SELECT * access_log
        WHERE time >= TIMESTAMP '2017-01-01 00:00:00'
    ) a
    JOIN users b ON b.id=a.user_id
    WHERE b.created_at = '2017-01-01'
    ```

1. 데이터 편향 피하기

    ```sql
    -- 비효율적인 쿼리 (distinct count는 분산되지 않아 처리가 오래 걸림)
    SELECT date, count(distinct user_id) users
    FROM access_log GROUP BY date

    -- 보다 효율적인 쿼리 (최초에 중복을 없앤다)
    SELECT date, count(*) users
    FROM(
        SELECT distinct date, user_id FROM access_log
    ) a
    GROUP BY date
    ```

#### 대화형 쿼리 엔진 Presto의 구조 
- `대화형 쿼리 엔진`: 쿼리 실행 지연을 감소하여 작은 쿼리를 여러 번 실행하는 엔진
- BigQuery Impala, Presto 등

`Presto`  
- 플러그인 가능한 스토리지
    - Hive와 같이 하나의 쿼리에서 `여러 개의 데이터 소스 연결 가능` (전용 스토리지 X)
        - Hive의 메타 스토어를 활용할 수 있음 → Hive와 연동성이 좋다
        - 열 지향 데이터 구조(ORC)로 되어있을 때 최대 성능 → 따라서 Hive에서 구조화된 데이터를 가져옴
    - MPP DB의 경우, 스토리지와 컴퓨팅 노드가 밀접한 연관
- CPU 처리의 최적화
    - 쿼리를 분석하여 최적의 실행 계획을 생성 → 워크 노드에 배포 → 병렬로 처리
    - CPU 이용 효율이 높음 (CPU와 메모리 성능이 좋으면 최대 성능)
    - 실행이 시작되면 중간에 끼어들 수 없음 → `너무 큰 쿼리 적합하지 않음`
- 인 메모리 처리에 의한 고속화
    - Hive와 달리 쿼리 실행 과정에서 디스크에 쓰지 않음
    - 메모리가 부족하면 여유가 생길 때까지 기다리거나 오류
    - 너무 오래 걸리는 작업은 Hive에 맡기는 게 좋음
- 분산 결합과 브로드캐스트 결합  
    테이블 결합 시 조인키를 메모리 상에 유지하는 방법
    - 분산 결합: 같은 키를 갖는 데이터는 동일한 노드에 모임 → 노드 간에 데이터 전송이 쿼리 지연을 초래함
    - 브로드캐스트 결합: 한쪽 테이블이 작을 경우, 결합하는 테이블에 모든 데이터가 각 노드에 복사된다
    <img src="https://user-images.githubusercontent.com/40620421/187230686-67a9ad4b-9954-4844-a251-5e96ba958357.png" width="350">
    <img src="https://user-images.githubusercontent.com/40620421/187230707-140fc800-3324-47d4-8b77-45a937e3b1e2.png" width="350">